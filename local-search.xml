<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>深度学习实践论文报告</title>
    <link href="/2025/07/08/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AF%BC%E8%AE%BA%E8%AE%BA%E6%96%87%E6%8A%A5%E5%91%8A/"/>
    <url>/2025/07/08/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AF%BC%E8%AE%BA%E8%AE%BA%E6%96%87%E6%8A%A5%E5%91%8A/</url>
    
    <content type="html"><![CDATA[<h2 id="Dynamic-LLaVA-Efficient-Multimodal-Large-Language-Models-via-Dynamic-Vision-Language-Context-Sparsification"><a href="#Dynamic-LLaVA-Efficient-Multimodal-Large-Language-Models-via-Dynamic-Vision-Language-Context-Sparsification" class="headerlink" title="Dynamic-LLaVA: Efficient Multimodal Large Language Models via Dynamic Vision-Language Context Sparsification"></a><strong>Dynamic-LLaVA: Efficient Multimodal Large Language Models via Dynamic Vision-Language Context Sparsification</strong></h2><p><strong>论文作者及其单位</strong></p><p><span style="font-size: 12px;"><strong>Wenxuan Huang</strong>, <strong>Shaohui Lin</strong><br>East China Normal University  </p><hr><h4 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a><strong>摘要</strong></h4><p><span style="font-size: 12px;">多模态大语言模型（MLLMs）在视觉理解和推理方面取得了显著成功，但解码过程中计算和内存需求逐渐增加。现有方法通过减少视觉上下文冗余提高效率，但这种效益在解码阶段逐渐减弱。为了解决这一问题，本文提出了动态视觉-语言上下文稀疏化框架 <strong>Dynamic-LLaVA</strong>，通过动态减少视觉上下文冗余并优化语言上下文的计算开销，提升了推理效率。<strong>Dynamic-LLaVA</strong>能够在预填充阶段减少约75%的计算消耗，并在解码过程中减少50%的计算和GPU内存开销。大量实验表明，<strong>Dynamic-LLaVA</strong>在不显著降低性能的情况下提高了推理效率，部分任务上甚至实现了性能提升。代码可在<a href="https://github.com/Osilly/dynamic_llava">GitHub</a>获取。</span></p><hr><h4 id="背景与动机"><a href="#背景与动机" class="headerlink" title="背景与动机"></a><strong>背景与动机</strong></h4><ol><li><p><strong>背景</strong><br><span style="font-size: 12px;">随着大规模语言模型（LLMs）的迅速发展，特别是在多模态领域，LLaVA范式成为了多模态大语言模型（MLLMs）中的主流方法。该范式通过特征提取器将视觉数据映射到LLM的特征空间，并显著提升了视觉理解、推理和交互能力。然而，LLM通常采用仅解码器的Transformer作为基本架构，并且通常包含非常多的参数。由于在解码过程中生成输出令牌，计算消耗逐渐增加，导致大量的计算负担。</span></p></li><li><p><strong>问题定义</strong><br><span style="font-size: 12px;">本文目标是提高多模态大语言模型（MLLMs）推理效率，尤其是解决在推理过程中，由于视觉上下文的冗余，导致计算和内存消耗逐渐增大的问题。动态视觉-语言上下文稀疏化是本文提出的核心解决方案。</span></p></li><li><p><strong>前人的方法的局限性</strong><br><span style="font-size: 12px;">现有的视觉上下文稀疏化方法，虽然能在预填充阶段减少视觉上下文的计算和内存开销，但随着解码过程的进行，这些方法的效率优势逐渐减小。这是因为在解码阶段，计算开销主要转移到文本生成的自回归过程中，视觉上下文的减少对推理效率的影响变得不再明显。</span></p></li><li><p><strong>论文贡献</strong><br><span style="font-size: 12px;">本文提出了<strong>Dynamic-LLaVA</strong>框架，作者引入了两个可学习的预测器，通过在预填充和解码阶段动态稀疏化视觉和语言上下文，分别减少计算消耗和内存开销。此外，本文还设计了适应不同推理模式（包括无KV缓存解码、有KV缓存解码）的稀疏化推理方案，并通过端到端训练优化稀疏化过程，以提高推理效率。同时开发了稀疏化推理的批处理并行策略。</span></p></li></ol><hr><h4 id="方法"><a href="#方法" class="headerlink" title="方法"></a><strong>方法</strong></h4><p><img src="/2025/07/08/hello-world/mage.png"><br><span style="font-size: 12px;"><strong>Dynamic-LLaVA</strong> 框架通过引入两个可学习的预测器$P^I$和$P^{OT} $来动态稀疏化视觉和语言上下文。这两个预测器生成二元掩码$M^I$和$M^{OT}$，以决定在第 l 个解码器层中是保留还是丢弃图像 token 和输出 token。这种一次性 token 减少策略避免了对 MLLM 解码器稀疏化比例进行复杂调整的需要。可学习的预测器由轻量级多层神经网络组成，仅引入了极小的额外计算成本（不到总成本的1%）。</span></p><p><span style="font-size: 12px;"> <strong>Dynamic-LLaVA</strong> 为 MLLM 的特定生成阶段（即预填充、不带 KV 缓存的解码和带 KV 缓存的解码）定制了不同的稀疏化策略:</p><ul><li><p><strong>预填充阶段</strong>：<br><span style="font-size: 12px;">在预填充阶段，只对图像 token 进行减少。图像预测器$P^I$利用图像 token 的特征来预测二元掩码$M^I$，以选择参与预填充计算的 token。减少后的图像token集$S_l^{I∗}$和文本 token 集 $S_l^T$一起进行计算。</p></li><li><p><strong>不带 KV 缓存的解码阶段</strong>：<br><span style="font-size: 12px;">此操作类似于预填充阶段，但最后一个输出 token 会生成下一个输出 token。<strong>Dynamic-LLaVA</strong> 使用 ( P^{OT} ) 和 ( S^{OT} ) 获取二元矩阵 ( M^{OT} )，并保留最后一个输出 token，从而获得稀疏化后的输出 token 集合 ( S^{OT*} )。在预填充和不带 KV 缓存的解码阶段，预测器减少 token 集 ( S_I ) 到 ( S_I^* )，所有后续层的 token 集进行计算，从而提高计算效率。</p></li><li><p><strong>带KV缓存的解码阶段</strong>：<br><span style="font-size: 12px;">主要目标是减少 KV 缓存的大小（特别是 ( S^K ) 和 ( S^V )）以节省 GPU 内存。<strong>Dynamic-LLaVA</strong> 使用最后一个输出 token ( S^{OT}<em>{N</em>{OT}} ) 和 ( P^{OT} ) 来获得一个二元矩阵 ( M^{OT}<em>{N</em>{OT}} )，该策略决定了当前输出 token 的 KV 激活是否添加到 KV 缓存中。这个决策会传递到后续层，相应地减少后续层的 KV 缓存大小。</p></li></ul><p><strong>端到端稀疏化训练</strong>：</p><p> <span style="font-size: 12px;">与稀疏化推理阶段直接减少 token 集不同，训练过程中全 token 集和二元矩阵来自优化器和LLM。为了解决不可微的 <code>argmax()</code> 操作和梯度流问题，<strong>Dynamic-LLaVA</strong> 使用了带有 Straight-Through 梯度估计器的 Gumbel-Softmax。除此之外，模型在训练中通过约束 token 集限制造成二元矩阵，以根据预定的 token 保留率进行稀疏化。为了避免在短输出 token 样本上稀疏化 ( S_l^{OT} ) 导致训练不稳定和性能下降，<strong>Dynamic-LLaVA</strong> 仅输出文本 token 长度超过预定 ( LEN^{OT} ) 的样本应用 ( S_l^{OT} ) 稀疏化。</p><p><span style="font-size: 12px;">具体来说，本文的核心贡献在于提出了一种新的稀疏化方法，可以同时稀疏化视觉上下文和语言上下文，且能够在不同的推理阶段动态调整稀疏化程度。</p><hr><h4 id="实验结果（性能分析）"><a href="#实验结果（性能分析）" class="headerlink" title="实验结果（性能分析）"></a><strong>实验结果（性能分析）</strong></h4><p><img src="/2025/07/08/hello-world/mage-1.png"><br><span style="font-size: 12px;">实验表明，<strong>Dynamic-LLaVA</strong>在预填充阶段的计算消耗减少了约 75%。能够在整个生成过程中显著减少计算消耗和内存占用，在没有KV缓存的解码阶段，计算消耗减少了约50%，而在有KV缓存的解码阶段，GPU内存占用减少了约50%。同时，在多个基准测试中，<strong>Dynamic-LLaVA</strong>保持了与全上下文推理相当的理解和生成能力，甚至在某些任务上取得了性能提升。</p><p><span style="font-size: 12px;">例如，在视觉理解基准测试中，<strong>Dynamic-LLaVA</strong>在减少视觉标记的同时，仍能取得与现有最先进方法相当的性能。在<strong>SciQA</strong>、<strong>POPE</strong>、<strong>MMBench</strong>等基准中，<strong>Dynamic-LLaVA</strong>分别在7B和13B模型上实现了+2.3%和+0.8%的性能提升。</p><hr><h4 id="优劣性与创新点分析"><a href="#优劣性与创新点分析" class="headerlink" title="优劣性与创新点分析"></a><strong>优劣性与创新点分析</strong></h4><ol><li><p><strong>创新点</strong>  </p><ul><li><span style="font-size: 12px;">提出了动态视觉-语言上下文稀疏化框架，通过动态调整稀疏化的程度，既减少了计算和内存开销，又保持了生成能力。</li><li><span style="font-size: 12px;">采用可学习的预测器进行稀疏化决策，并结合Gumbel-Softmax进行端到端训练，避免了梯度流问题，保证了训练和推理的一致性。</li></ul></li><li><p><strong>优点</strong>  </p><ul><li><span style="font-size: 12px;"><strong>显著提高效率</strong>：<strong>Dynamic-LLaVA</strong>能在整个推理过程中显著降低计算和内存开销，尤其在没有KV缓存的解码阶段，推理速度提升了50%。</li><li><span style="font-size: 12px;"><strong>低性能损失</strong>：在减少计算和内存占用的同时，模型的理解和生成能力几乎未受影响，部分任务甚至取得了性能提升。</li></ul></li><li><p><strong>不足之处</strong>  </p><ul><li><span style="font-size: 12px;"> 对短输出文本 token 的样本进行稀疏化可能会导致训练不稳定和性能下降。在极端场景下，过度稀疏化可能会对生成质量产生一定影响，尤其是在生成较长文本时，模型的生成能力可能会略有下降，在某些复杂任务上，同时进行视觉和语言稀疏化可能需要更精细的平衡。</li></ul></li></ol><hr><h4 id="总结与思考"><a href="#总结与思考" class="headerlink" title="总结与思考"></a><strong>总结与思考</strong></h4><p><span style="font-size: 12px;">本论文提出的<strong>Dynamic-LLaVA</strong>框架为多模态大语言模型的推理效率提供了有效的解决方案。通过动态稀疏化视觉和语言上下文，显著减少了计算和内存开销，尤其是在解码阶段表现优异。此外，尽管本文方法取得了良好的推理效率，未来可以进一步研究如何在更大规模的数据集和更复杂的推理任务中优化这一框架，以进一步提升推理效率和生成质量。</p><p><span style="font-size: 12px;">论文强调了动态稀疏化在整个生成过程中的持续效率提升，这与以往主要关注预填充阶段的方法形成了鲜明对比。这种动态调整资源分配的能力对于实际部署中的 MLLM 至关重要，尤其是在资源受限的环境下。未来的研究可以进一步探索更细粒度的动态稀疏化机制，例如根据任务复杂性或用户反馈实时调整稀疏化程度。该框架具有可集成性，还可能推广到其他 MLLM 架构，甚至未来的多模态模型。如何将这种稀疏化方法应用于更广泛的多模态任务（如视频理解、音频-视觉融合）是一个很值得期待的方向。批并行策略的引入充分利用了 GPU 硬件优势。更深层次的软硬件协同设计将是提升 MLLM 效率的关键。例如，定制化硬件加速器可以更好地支持这种动态稀疏化操作，从而实现更好的性能-效率平衡。</p><hr>]]></content>
    
    
    
    <tags>
      
      <tag>用于学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>测试文章</title>
    <link href="/2025/07/08/%E6%B5%8B%E8%AF%95%E6%96%87%E7%AB%A0/"/>
    <url>/2025/07/08/%E6%B5%8B%E8%AF%95%E6%96%87%E7%AB%A0/</url>
    
    <content type="html"><![CDATA[<h1 id="这是一篇测试文章"><a href="#这是一篇测试文章" class="headerlink" title="这是一篇测试文章"></a>这是一篇测试文章</h1><p><img src="/2025/07/08/hello-world/g"></p>]]></content>
    
    
    
    <tags>
      
      <tag>用于学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2025/07/08/hello-world/"/>
    <url>/2025/07/08/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
